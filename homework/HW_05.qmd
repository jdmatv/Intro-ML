---
title: "Homework 5"
format: 
    html:
        embed-resources: true
---


__Due Date:__ 2024-11-20 at 8:30 AM PT
---


__Name:__ Joseph Matveyenko


## Preparation

1. We're using the same [data file](https://github.com/gabehassler/PRGS-Intro-to-ML-2024/blob/main/data/processed/svi_covid.csv) from GitHub as the last assignment.
If should be in the _data/processed_ folder.



## Homework - Neural Newtorks

1. Use a simple neural network to predict the number of per-capita COVID-19 deaths in each county in the US using the SVI variables.
The outcome variable is `total_deaths_per_100k` and the predictor variables are `EP_POV150, EP_UNEMP, EP_HBURD, EP_NOHSDP, EP_UNINSUR, EP_AGE65, EP_AGE17, EP_DISABL, EP_SNGPNT, EP_LIMENG, EP_MINRTY, EP_MUNIT, EP_MOBILE, EP_CROWD, EP_NOVEH, EP_GROUPQ, EP_NOINT`.
The neural network should have one hidden layer with 10 nodes and use the ReLU activation function.
Plot the predicted values against the true values.
What is the mean squared error of the predictions in the test set?

Loading in the data
```{python}
import os
import pandas as pd

# set working dir to main
if (os.getcwd().split(os.sep)[-1]) == 'homework':
    os.chdir(os.pardir)

# load pre-processed data and ensure FIPS is read as a string
dat_path = "data/processed/svi_covid.csv"
svi_covid = pd.read_csv(dat_path, dtype={'fips_code': str}).drop('Unnamed: 0', axis=1)
svi_covid.head(5)
```

Run a simple neural net using code by Gabe Hassler (PyTorch)
```{python}
# load packages
import torch
from torch import nn
from torch.utils.data import random_split
from torch.utils.data import DataLoader, Dataset
import numpy as np

torch.manual_seed(666) # for reproducibility

# special PyTorch class for loading data
class PandasDataset(Dataset):
    def __init__(self, dataframe, predictors, outcome):
        x = np.array(dataframe[predictors].values).reshape(-1, len(predictors))
        y = np.array(dataframe[outcome].values).reshape(-1, 1)
        self.x = torch.tensor(x, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.float32)

    def __len__(self):
        return len(self.x)

    def __getitem__(self, idx):
        return self.x[idx], self.y[idx]

# load data into class
outcome = svi_covid.columns[2]
predictors = 'EP_POV150, EP_UNEMP, EP_HBURD, EP_NOHSDP, EP_UNINSUR, EP_AGE65, EP_AGE17, EP_DISABL, EP_SNGPNT, EP_LIMENG, EP_MINRTY, EP_MUNIT, EP_MOBILE, EP_CROWD, EP_NOVEH, EP_GROUPQ, EP_NOINT'.split(', ')
dataset = PandasDataset(svi_covid, predictors, outcome)

# split into training and test sets
train_perc = 0.8 # 80% of the data will be used for training
train_size = int(train_perc * len(dataset))
test_size = len(dataset) - train_size
train_dataset, test_dataset = random_split(dataset, [train_size, test_size])

# where/how will the code run?
device = (
    "cuda"
    if torch.cuda.is_available()
    else "mps"
    if torch.backends.mps.is_available()
    else "cpu"
)
print(f"Using {device} device")

input_features = len(predictors)

# define neural net
class NeuralNetwork(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear_relu_stack = nn.Sequential(
            # you will want to play with the code below
            nn.Linear(input_features, 10), # the first number is the number of input features
            nn.ReLU(),
            nn.Linear(10, 1), # the second number is the number of output features
        )

    def forward(self, x):
        estimates = self.linear_relu_stack(x)
        return estimates

model = NeuralNetwork().to(device) # load the model onto the appropriate device

# define loss function
loss_fn = nn.MSELoss()

# define optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)

def train(dataloader, model, loss_fn, optimizer, losses):
    size = len(dataloader.dataset)
    num_batches = len(dataloader)
    model.train()
    train_loss = 0
    for batch, (X, y) in enumerate(dataloader):
        X, y = X.to(device), y.to(device)

        # Compute prediction error
        pred = model(X)
        loss = loss_fn(pred, y)

        # Backpropagation
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()

        train_loss += loss.item()
    train_loss /= num_batches
    losses.append(train_loss)

def test(dataloader, model, loss_fn, losses):
    size = len(dataloader.dataset)
    num_batches = len(dataloader)
    model.eval()
    test_loss = 0
    with torch.no_grad():
        for X, y in dataloader:
            X, y = X.to(device), y.to(device)
            pred = model(X)
            test_loss += loss_fn(pred, y).item()
    test_loss /= num_batches
    losses.append(test_loss)
```

Now, we can train the neural network.
```{python}
batch_size = 64 # number of observations to use in each iteration
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)

train_losses = []
test_losses = []

epochs = 15 # you will want to play with this number
for t in range(epochs):
    train(train_loader, model, loss_fn, optimizer, train_losses)
    test(test_loader, model, loss_fn, test_losses)
print("Done!")
```

Next, we plot the losses
```{python}
import matplotlib.pyplot as plt

plt.plot(train_losses, label="train")
plt.plot(test_losses, label="test")
plt.legend()
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.show()
```

2. Repeat the analysis from the previous question, but this time use a more complicated neural network with more hidden layers and/or more nodes in the hidden layers.
You should experiment with different architectures and activation functions to see what works best.
Plot the predicted values against the true values.
What is the mean squared error of the predictions in the test set?

3. Compare the predictions of the neural network in Question 2 to the predictions of the regression tree from the previous assignment. Which model would you use to predict the number of per-capita COVID-19 deaths? Why?
Which model would you use to understand the relationship between the SVI variables and the number of per-capita COVID-19 deaths? Why?